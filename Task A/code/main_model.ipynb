{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:12.855500700Z",
     "start_time": "2023-08-17T11:14:09.586419200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yegmo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import arabicstopwords.arabicstopwords as ar_stp\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers import evaluation\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from snowballstemmer import stemmer\n",
    "from torch import nn\n",
    "# from simcse import SimSCE\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# torch.cude.empty_cache\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:12.919513Z",
     "start_time": "2023-08-17T11:14:12.855500700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.device_count())\n",
    "# print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:12.919513Z",
     "start_time": "2023-08-17T11:14:12.903511Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T08:04:53.469544200Z",
     "start_time": "2023-08-11T08:04:53.454643500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "index_path = os.path.join(data_path, \"QPC_Index/data.properties\")\n",
    "\n",
    "query_train_path = os.path.join(data_path, \"QQA23_TaskA_train.tsv\")\n",
    "query_dev_path = os.path.join(data_path, \"QQA23_TaskA_dev.tsv\")\n",
    "query_test_path = os.path.join(data_path, \"QQA23_TaskA_test.tsv\")\n",
    "\n",
    "passage_path = os.path.join(data_path, \"Thematic_QPC/QQA23_TaskA_QPC_v1.1.tsv\")\n",
    "\n",
    "qp_pair_train_path = os.path.join(data_path, \"qrels\\QQA23_TaskA_qrels_train.gold\")\n",
    "qp_pair_dev_path = os.path.join(data_path, \"qrels\\QQA23_TaskA_qrels_dev.gold\")\n",
    "\n",
    "task_B_train_path = os.path.join(data_path, \"Task B data/QQA23_TaskB_qrcd_v1.2_train_preprocessed.jsonl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:12.934688500Z",
     "start_time": "2023-08-17T11:14:12.919513Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read file"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T05:37:35.422287500Z",
     "start_time": "2023-08-11T05:37:35.406190400Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# read file based on its extension (tsv or xlsx)\n",
    "def read_file(input_file, sep=\"\\t\", names = \"\"):\n",
    "    if input_file.endswith(\".xlsx\"):\n",
    "        df = pd.read_excel(input_file)\n",
    "    else:\n",
    "        if names != \"\":\n",
    "            df = pd.read_csv(input_file, sep=sep, names=names,encoding=\"utf-8\")\n",
    "        else:\n",
    "            df = pd.read_csv(input_file, sep=sep,encoding=\"utf-8\")\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:14.771326500Z",
     "start_time": "2023-08-17T11:14:14.763298100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "qrels_columns = [\"qid\", \"Q0\", \"docid\", \"relevance\"]\n",
    "\n",
    "def read_qrels_file(qrels_file):\n",
    "    # split_token = '\\t' if format_checker.is_tab_sparated(qrels_file) else  \"\\s+\"\n",
    "    df_qrels = pd.read_csv(qrels_file, sep='\\t', names=qrels_columns)\n",
    "    df_qrels[\"qid\"] = df_qrels[\"qid\"].astype(str)\n",
    "    df_qrels[\"docid\"] = df_qrels[\"docid\"].astype(str)\n",
    "    return df_qrels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:15.669526300Z",
     "start_time": "2023-08-17T11:14:15.637462800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def load_index(index_path):\n",
    "    if not pt.started():\n",
    "        pt.init(helper_version=\"0.0.6\")\n",
    "\n",
    "    try:\n",
    "        index = pt.IndexFactory.of(index_path)\n",
    "        print(\"Index was loaded successfully from this path: \", index_path)\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print('Cannot load the index, check exception details {}'.format(e))\n",
    "        return []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:16.702571300Z",
     "start_time": "2023-08-17T11:14:16.686570700Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T05:37:37.652006400Z",
     "start_time": "2023-08-11T05:37:37.639499500Z"
    }
   },
   "source": [
    "## Cleaning & Preprocessing\n",
    "Clean text from urls, handles, special characters, tabs, line jumps, extra white space, and puntuations.\n",
    "Preprocess the arabic input text by performing normalization, stemming, and removing stop words."
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:17.850712300Z",
     "start_time": "2023-08-17T11:14:17.842706300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean text from urls, handles, special characters, tabs, line jumps, and extra white space.\n",
    "def clean(text):\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)  # remove urls\n",
    "    text = re.sub(r\"@[\\w]*\", \" \", text)  # remove handles\n",
    "    text = re.sub(r\"[\\.\\,\\#_\\|\\:\\?\\?\\/\\=]\", \" \", text) # remove special characters\n",
    "    text = re.sub(r\"\\t\", \" \", text)  # remove tabs\n",
    "    text = re.sub(r\"\\n\", \" \", text)  # remove line jump\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # remove extra white space\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Removing punctuations in string using regex\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:18.599830300Z",
     "start_time": "2023-08-17T11:14:18.591830Z"
    }
   },
   "outputs": [],
   "source": [
    "# arabic stemmer\n",
    "ar_stemmer = stemmer(\"arabic\")\n",
    "\n",
    "# remove arabic stop words\n",
    "def ar_remove_stop_words(sentence):\n",
    "    terms=[]\n",
    "    stopWords= set(ar_stp.stopwords_list())\n",
    "    for term in sentence.split() : \n",
    "        if term not in stopWords :\n",
    "            terms.append(term)\n",
    "    return \" \".join(terms)\n",
    "\n",
    "\n",
    "# normalize the arabic text\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    return(text)\n",
    "\n",
    "# stem the arabic text\n",
    "def ar_stem(sentence):\n",
    "    return \" \".join([ar_stemmer.stemWord(i) for i in sentence.split()])\n",
    "\n",
    "\n",
    "# apply all preprocessing steps needed for Arabic text\n",
    "def preprocess_arabic(text): \n",
    "    text = normalize_arabic(text)\n",
    "    text = ar_remove_stop_words(text)\n",
    "    text = ar_stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def prepare_data(path, column, id_type, id_column='docno'):\n",
    "        df = read_file(path, names=['docno', 'text'])\n",
    "\n",
    "        df[column] = df['text'].apply(clean)\n",
    "        df[column] = df[column].apply(preprocess_arabic)\n",
    "\n",
    "        df[id_type] = df[id_column].astype(str) # convert the id column to string\n",
    "        df = df[[id_type, 'text', column]] # keep the columns needed for search\n",
    "\n",
    "        print(f\"Done with preparation with {column}!\")\n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:19.076564900Z",
     "start_time": "2023-08-17T11:14:19.060560300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T05:37:39.775198Z",
     "start_time": "2023-08-11T05:37:39.759112600Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index was loaded successfully from this path:  ../data\\QPC_Index/data.properties\n"
     ]
    }
   ],
   "source": [
    "index = load_index(index_path=index_path)\n",
    "\n",
    "# print(index.getCollectionStatistics().toString())\n",
    "# print(index.getMetaIndex().getKeys())\n",
    "# for kv in index.getLexicon():\n",
    "#     print((kv.getKey())+\"\\t\"+ kv.getValue().toString())\n",
    "# index.getLexicon()[\"فاعل\"].toString()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:21.059932100Z",
     "start_time": "2023-08-17T11:14:20.634160400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with preparation with passage!\n",
      "Done with preparation with query!\n",
      "Done with preparation with query!\n",
      "Done with preparation with query!\n"
     ]
    }
   ],
   "source": [
    "df_passage = prepare_data(passage_path, 'passage', 'pid')\n",
    "\n",
    "df_query_train = prepare_data(query_train_path, 'query', 'qid')\n",
    "df_query_dev = prepare_data(query_dev_path, 'query', 'qid')\n",
    "df_query_test = prepare_data(query_test_path, 'query', 'qid')\n",
    "\n",
    "df_qppair_train = read_qrels_file(qp_pair_train_path)\n",
    "\n",
    "df_qppair_dev = read_qrels_file(qp_pair_dev_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:25.590539400Z",
     "start_time": "2023-08-17T11:14:21.715916600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model - Sentence Embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def save_query_passage_retrieval(result, tag, run_save=False, df_query=df_query_train, top_k=10):\n",
    "    if tag == \"BM25\":\n",
    "        result[\"Q0\"] = [\"Q0\"] * len(result)\n",
    "        result[\"tag\"] = [tag] * len(result)\n",
    "        result['qid'] = result[\"qid\"]\n",
    "        result['pid'] = result[\"docno\"]\n",
    "        tag = \"BM25_Final\"\n",
    "        result = result[[\"qid\", \"Q0\", \"pid\", \"rank\", \"score\", \"tag\"]]\n",
    "\n",
    "    elif \"SimCSE_bi\" in tag:\n",
    "        np_result = np.array(result).flatten()\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        result[\"qid\"] = df_query[\"qid\"].tolist() * top_k\n",
    "        result = result.sort_values(by=['qid']).reset_index(drop=True)\n",
    "        result[\"Q0\"] = [\"Q0\"] * len(result)\n",
    "        result[\"pid\"] = [df_passage.iloc[x['corpus_id']]['pid'] for x in np_result]\n",
    "        result[\"rank\"] = list(range(1, top_k+1)) * len(df_query)\n",
    "        result[\"score\"] = [x['score'] for x in np_result]\n",
    "        result[\"tag\"] = [tag] * len(np_result)\n",
    "\n",
    "    elif tag == \"SimCSE_bmbiencd\":\n",
    "        df_result = pd.DataFrame()\n",
    "        for i in range(len(bm25_biencoder_hit)):\n",
    "            for j in range(len(bm25_biencoder_hit[i])):\n",
    "                new_record = pd.DataFrame([{\"qid\": df_query_dev['qid'].tolist()[i],\n",
    "                        \"Q0\": \"Q0\",\n",
    "                        \"pid\": bm25_biencoder_hit[i][j]['corpus_id'],\n",
    "                        \"rank\": j,\n",
    "                        \"score\": bm25_biencoder_hit[i][j]['score'],\n",
    "                        \"tag\": tag\n",
    "                    }])\n",
    "                df_result = pd.concat([df_result, new_record], ignore_index=True)\n",
    "        result = df_result\n",
    "        print(type(result))\n",
    "\n",
    "    elif tag == \"SimCSE_cross\":\n",
    "        result['tag'] = tag\n",
    "        result['Q0'] = 'Q0'\n",
    "        result = result[[\"qid\", \"Q0\", \"pid\", \"rank\", \"score\", \"tag\"]]\n",
    "\n",
    "    if run_save:\n",
    "        run_save_path = os.path.join(data_path, f\"runs/{tag}.tsv\")\n",
    "        # print(run_save_path)\n",
    "        result.to_csv(run_save_path, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:25.601150800Z",
     "start_time": "2023-08-17T11:14:25.593120300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert Data to SentenceTransformer InputFormat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Simple passage-passage pair"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_samples_passage) = 1266\n"
     ]
    }
   ],
   "source": [
    "train_samples_passage = []\n",
    "for _, row in df_passage.iterrows():\n",
    "    train_samples_passage.append(InputExample(texts=[row['passage'], row['passage']]))\n",
    "\n",
    "print(\"len(train_samples_passage) =\", len(train_samples_passage))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:28.604099Z",
     "start_time": "2023-08-17T11:14:28.555577100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### query-passage double pair with relevance label = 1 (positive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_samples_qp) = 1892\n"
     ]
    }
   ],
   "source": [
    "train_samples_qp = []\n",
    "for _, row in df_qppair_train.iterrows():\n",
    "    query_id = row['qid']\n",
    "    query = df_query_train[df_query_train['qid'] == query_id]['query'].tolist()[0]\n",
    "    passage_id = row['docid']\n",
    "\n",
    "    if passage_id == '-1':\n",
    "        continue\n",
    "    else:\n",
    "        passage = df_passage[df_passage['pid'] == passage_id]['passage'].tolist()[0]\n",
    "        label = row['relevance']\n",
    "        #positive sample\n",
    "        train_samples_qp.append(InputExample(texts=[query, passage], label=label))\n",
    "        train_samples_qp.append(InputExample(texts=[passage, query], label=label))\n",
    "\n",
    "print(\"len(train_samples_qp) =\", len(train_samples_qp))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:29.395010500Z",
     "start_time": "2023-08-17T11:14:29.055581100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### contrastive: query-passage double pair with relevance label = 1 (positive) and not found BM25 top-k passages with relevance label = 0 (negative)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k = 1000\n",
      "len(train_samples_qp_contrastive) = 87784\n"
     ]
    }
   ],
   "source": [
    "train_samples_qp_contrastive = []\n",
    "\n",
    "top_k = 1000\n",
    "print(\"top_k =\", top_k)\n",
    "BM25_model = pt.BatchRetrieve(index, controls = {\"wmodel\": \"BM25\"}, num_results=top_k)\n",
    "\n",
    "for _, row in df_qppair_train.groupby('qid'):\n",
    "    query_id = row['qid'].tolist()[0]\n",
    "    query = df_query_train[df_query_train['qid'] == query_id]['query'].tolist()[0]\n",
    "    bm25_related_passage = BM25_model.search(query)['docno'].tolist()\n",
    "    positive_passage = row['docid'].tolist()\n",
    "    negative_passage = list(set(bm25_related_passage) - set(positive_passage))\n",
    "\n",
    "    for pos_passage in positive_passage:\n",
    "        if pos_passage == '-1':\n",
    "            continue\n",
    "        else:\n",
    "            passage = df_passage[df_passage['pid'] == pos_passage]['passage'].tolist()[0]\n",
    "            label = 1\n",
    "            #positive sample\n",
    "            train_samples_qp_contrastive.append(InputExample(texts=[query, passage], label=label))\n",
    "            train_samples_qp_contrastive.append(InputExample(texts=[passage, query], label=label))\n",
    "\n",
    "    for neg_passage in negative_passage:\n",
    "        if neg_passage == '-1':\n",
    "            continue\n",
    "        else:\n",
    "            passage = df_passage[df_passage['pid'] == neg_passage]['passage'].tolist()[0]\n",
    "            label = 0\n",
    "            #positive sample\n",
    "            train_samples_qp_contrastive.append(InputExample(texts=[query, passage], label=label))\n",
    "            train_samples_qp_contrastive.append(InputExample(texts=[passage, query], label=label))\n",
    "\n",
    "print(\"len(train_samples_qp_contrastive) =\", len(train_samples_qp_contrastive))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:39.660228Z",
     "start_time": "2023-08-17T11:14:30.191293700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### multiple negative ranking: query-passage double pair with relevance label = 1 (positive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_samples_qp_multiple_negative_ranking) = 1892\n"
     ]
    }
   ],
   "source": [
    "train_samples_qp_multiple_negative_ranking = []\n",
    "for _, row in df_qppair_train.groupby('qid'):\n",
    "    query_id = row['qid'].tolist()[0]\n",
    "    query = df_query_train[df_query_train['qid'] == query_id]['query'].tolist()[0]\n",
    "    positive_passage = row['docid'].tolist()\n",
    "    for pos_passage in positive_passage:\n",
    "        if pos_passage == '-1':\n",
    "            continue\n",
    "        else:\n",
    "            passage = df_passage[df_passage['pid'] == pos_passage]['passage'].tolist()[0]\n",
    "            label = 1\n",
    "            #positive sample\n",
    "            train_samples_qp_multiple_negative_ranking.append(InputExample(texts=[query, passage], label=label))\n",
    "            train_samples_qp_multiple_negative_ranking.append(InputExample(texts=[passage, query], label=label))\n",
    "\n",
    "print(\"len(train_samples_qp_multiple_negative_ranking) =\", len(train_samples_qp_multiple_negative_ranking))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:39.868789400Z",
     "start_time": "2023-08-17T11:14:39.660228Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### triple: query-positive passage-negative passage; negative passage is not found in BM25 top-k passages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k = 100\n",
      "len train_samples_qp_triple = 59120\n"
     ]
    }
   ],
   "source": [
    "top_k = 100\n",
    "print(\"top_k =\", top_k)\n",
    "BM25_model = pt.BatchRetrieve(index, controls = {\"wmodel\": \"BM25\"}, num_results=top_k)\n",
    "\n",
    "train_samples_qp_triple = []\n",
    "\n",
    "for _, row in df_qppair_train.groupby('qid'):\n",
    "    # print(row)\n",
    "    query_id = row['qid'].tolist()[0]\n",
    "    query = df_query_train[df_query_train['qid'] == query_id]['query'].tolist()[0]\n",
    "    bm25_related_passage = BM25_model.search(query)['docno'].tolist()\n",
    "    positive_passage = row['docid'].tolist()\n",
    "    negative_passage = list(set(bm25_related_passage) - set(positive_passage))\n",
    "    # print(bm25_related_passage)\n",
    "    # print(possitive_passage)\n",
    "    # print(negative_passage)\n",
    "\n",
    "    for pos_passage_id in positive_passage:\n",
    "        for neg_passage_id in negative_passage:\n",
    "            if pos_passage_id == '-1':\n",
    "                continue\n",
    "            else:\n",
    "                pos_passage = df_passage[df_passage['pid'] == pos_passage_id]['passage'].tolist()[0]\n",
    "                neg_passage = df_passage[df_passage['pid'] == neg_passage_id]['passage'].tolist()[0]\n",
    "                train_samples_qp_triple.append(InputExample(texts=[query, pos_passage, neg_passage]))\n",
    "\n",
    "print(\"len train_samples_qp_triple =\", len(train_samples_qp_triple))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:14:59.654179100Z",
     "start_time": "2023-08-17T11:14:39.868789400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mr. TyDi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_samples_mr_tydi_triple) = 362146\n"
     ]
    }
   ],
   "source": [
    "train_samples_mr_tydi_triple = []\n",
    "#https://huggingface.co/datasets/castorini/mr-tydi\n",
    "mr_tydi_dataset = load_dataset(\"castorini/mr-tydi\", \"arabic\", split=\"train\").to_pandas()\n",
    "\n",
    "for _, row in mr_tydi_dataset.iterrows():\n",
    "    query = row['query']\n",
    "    positive_passages = row['positive_passages']\n",
    "    negative_passages = row['negative_passages']\n",
    "\n",
    "    for pos_passage in positive_passages:\n",
    "        for neg_passage in negative_passages:\n",
    "            train_samples_mr_tydi_triple.append(InputExample(texts=[query, pos_passage, neg_passage]))\n",
    "\n",
    "print(\"len(train_samples_mr_tydi_triple) =\", len(train_samples_mr_tydi_triple))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:15:02.769953300Z",
     "start_time": "2023-08-17T11:14:59.654179100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task B Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 992 records from ../data\\Task B data/QQA23_TaskB_qrcd_v1.2_train_preprocessed.jsonl\n",
      "len(train_samples_qp_task_B) = 992\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data\n",
    "\n",
    "\n",
    "train_samples_qp_task_B = []\n",
    "train_passage_question_objects_task_B  = load_jsonl(task_B_train_path)\n",
    "for passage_question_object in train_passage_question_objects_task_B:\n",
    "    query = passage_question_object[\"question\"]\n",
    "    passage = passage_question_object[\"passage\"]\n",
    "    if len(passage_question_object[\"answers\"]) > 0:\n",
    "        train_samples_qp_task_B.append(InputExample(texts=[query, passage], label=1))\n",
    "    else:\n",
    "        train_samples_qp_task_B.append(InputExample(texts=[query, passage], label=0))\n",
    "\n",
    "train_passage_question_objects_task_B = pd.DataFrame(train_passage_question_objects_task_B)\n",
    "print(\"len(train_samples_qp_task_B) =\", len(train_samples_qp_task_B))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:15:02.826346Z",
     "start_time": "2023-08-17T11:15:02.769953300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TSDAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_tsdae = True\n",
    "model_name = 'aubmindlab/bert-base-arabert'\n",
    "batch_size = 8\n",
    "num_epochs = 8\n",
    "\n",
    "if run_tsdae:\n",
    "    # Define your sentence transformer model using CLS pooling\n",
    "\n",
    "\n",
    "    word_embedding_model = models.Transformer(model_name)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "    # Define a list with sentences (1k - 100k sentences)\n",
    "    train_sentences = df_passage['passage'].tolist()\n",
    "\n",
    "    # Create the special denoising dataset that adds noise on-the-fly\n",
    "    train_dataset = datasets.DenoisingAutoEncoderDataset(train_sentences)\n",
    "\n",
    "    # DataLoader to batch your data\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    train_samples_qp_task_B_dataloader = DataLoader(train_samples_qp_task_B, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Use the denoising auto-encoder loss\n",
    "    train_loss = losses.DenoisingAutoEncoderLoss(model, decoder_name_or_path=model_name, tie_encoder_decoder=True)\n",
    "    constraint_loss = losses.ContrastiveLoss(model)\n",
    "\n",
    "    # Call the fit method\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss), (train_samples_qp_task_B_dataloader, constraint_loss)],\n",
    "        epochs=num_epochs,\n",
    "        weight_decay=0,\n",
    "        scheduler='constantlr',\n",
    "        optimizer_params={'lr': 3e-5},\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    model.save(os.path.join(data_path, f'fine_tune/tsdae-model-v1'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SimCSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_simcse = False\n",
    "model_name = 'aubmindlab/bert-base-arabert'\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "\n",
    "if run_simcse:\n",
    "    # Define your sentence transformer model using CLS pooling\n",
    "    word_embedding_model = models.Transformer(model_name, max_seq_length=164)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "    # Define a list with sentences (1k - 100k sentences)\n",
    "    train_sentences = df_passage['passage'].tolist()\n",
    "\n",
    "    # Convert train sentences to sentence pairs\n",
    "    train_data = [InputExample(texts=[s, s]) for s in train_sentences]\n",
    "\n",
    "    # DataLoader to batch your data\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    train_samples_qp_task_B_dataloader = DataLoader(train_samples_qp_task_B, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Use the MultipleNegativesRankingLoss loss\n",
    "    train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "    constraint_loss = losses.ContrastiveLoss(model)\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss), (train_samples_qp_task_B_dataloader, constraint_loss)],\n",
    "        epochs=num_epochs,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # model.save(os.path.join(data_path, f'fine_tune/simcse-model'))\n",
    "    # model.save(os.path.join(data_path, 'fine_tune/simcse-model-v1'))\n",
    "    # model.save(os.path.join(data_path, 'fine_tune/simcse-model-v2'))\n",
    "    # model.save(os.path.join(data_path, 'fine_tune/simcse-model-v3'))\n",
    "    # model.save(os.path.join(data_path, 'fine_tune/simcse-model-v4'))\n",
    "    model.save(os.path.join(data_path, 'fine_tune/simcse-model-v5'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CT (Semantic Re-Tuning With Contrastive Tension (CT))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_ct = False\n",
    "if run_ct:\n",
    "    # Define your sentence transformer model using CLS pooling\n",
    "    model_name = 'aubmindlab/bert-base-arabert'\n",
    "    word_embedding_model = models.Transformer(model_name, max_seq_length=164)\n",
    "    # Apply mean pooling to get one fixed sized sentence vector\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "    # Define a list with sentences (1k - 100k sentences)\n",
    "    train_sentences = df_passage['passage'].tolist()\n",
    "\n",
    "    # For ContrastiveTension we need a special data loader to construct batches with the desired properties\n",
    "    train_dataloader =  losses.ContrastiveTensionDataLoader(train_sentences, batch_size=64, pos_neg_ratio=8)\n",
    "\n",
    "    # As loss, we losses.ContrastiveTensionLoss\n",
    "    train_loss = losses.ContrastiveTensionLoss(model)\n",
    "    num_epochs = 8\n",
    "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "    logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "              epochs=num_epochs,\n",
    "              optimizer_class=torch.optim.RMSprop,\n",
    "              optimizer_params={'lr': 5e-5},\n",
    "              show_progress_bar=True,\n",
    "              use_amp=False  # Set to True, if your GPU supports FP16 cores\n",
    "              )\n",
    "\n",
    "    model.save(data_path, f'fine_tune/ct-model')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CT In Batch Negative"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Define your sentence transformer model using CLS pooling\n",
    "# model_name = 'aubmindlab/bert-base-arabert'\n",
    "# word_embedding_model = models.Transformer(model_name, max_seq_length=164)\n",
    "# # Apply mean pooling to get one fixed sized sentence vector\n",
    "# pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "# model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#\n",
    "# # Define a list with sentences (1k - 100k sentences)\n",
    "# train_sentences = df_passage['passage'].tolist()\n",
    "#\n",
    "# # A regular torch DataLoader and as loss we use losses.ContrastiveTensionLossInBatchNegatives\n",
    "# train_dataloader = DataLoader(train_sentences, batch_size=64, shuffle=True, drop_last=True)\n",
    "# train_loss = losses.ContrastiveTensionLossInBatchNegatives(model)\n",
    "#\n",
    "# num_epochs = 8\n",
    "# warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "# logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "#\n",
    "# # Train the model\n",
    "# model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "#           epochs=num_epochs,\n",
    "#           optimizer_class=torch.optim.RMSprop,\n",
    "#           optimizer_params={'lr': 5e-5},\n",
    "#           show_progress_bar=True,\n",
    "#           use_amp=False  # Set to True, if your GPU supports FP16 cores\n",
    "#           )\n",
    "#\n",
    "# # model.save(data_path, f'fine_tune/ct-model')\n",
    "# model.save(data_path, f'fine_tune/ct-in-batch-negative-model')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Bi-Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T05:41:25.811358200Z",
     "start_time": "2023-08-11T05:40:51.432672100Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/pretrained_models.html\n",
    "# https://www.sbert.net/docs/pretrained-models/msmarco-v3.html\n",
    "\n",
    "num_epochs = 3\n",
    "train_batch_size = 64\n",
    "\n",
    "################# fine tune #################\n",
    "# bi_model_name = \"data_path, f'model/fine_tune/tsdae-model\"\n",
    "# bi_model_name = \"fine_tune/tsdae-model\"\n",
    "\n",
    "\n",
    "bi_model_name = os.path.join(data_path, \"fine_tune/simcse-model\") # Best\n",
    "# bi_model_name = os.path.join(data_path, \"fine_tune/simcse-model-v1\")\n",
    "# bi_model_name = os.path.join(data_path, \"fine_tune/simcse-model-v2\")\n",
    "# bi_model_name = os.path.join(data_path, \"fine_tune/simcse-model-v4\")\n",
    "# bi_model_name = os.path.join(data_path, \"fine_tune/simcse-model-v5\")\n",
    "\n",
    "# bi_model_name = os.path.join(data_path, \"fine_tune/tsdae-model-v1\")\n",
    "\n",
    "\n",
    "# bi_model_name = \"fine_tine/ct-model\"\n",
    "# bi_model_name = \"fine_tine/simcse-model-paraphrase-multilingual-mpnet-base-v2\"\n",
    "\n",
    "####################################### Our Best Models #######################################\n",
    "# bi_model_name = \"aubmindlab/bert-base-arabert\"\n",
    "# bi_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "#\n",
    "####################################### TODO: try other models\n",
    "# bi_model_name = \"xlm-roberta-base\"\n",
    "# bi_model_name = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\"\n",
    "# bi_model_name = \"sentence-transformers/msmarco-distilbert-base-v4\"\n",
    "\n",
    "# bi_model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "# bi_model_name = \"aubmindlab/araelectra-base-discriminator\"\n",
    "# bi_model_name = \"aubmindlab/bert-base-arabertv01\"\n",
    "# bi_model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "# bi_model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "\n",
    "# i guess this is not a good model for this task but we should try\n",
    "#bi_model_name = \"gfdgdfgdg/arap_qa_bert\" # run 5 : pAP@10 = 0.184\n",
    "#bi_model_name = \"gfdgdfgdg/arap_qa_bert_large_v2\" # run6 : pAP@10 = 0.372\n",
    "#bi_model_name = \"gfdgdfgdg/arap_qa_bert_v2\" # run7 : pAP@10 = 0.344\n",
    "#bi_model_name = \"zohaib99k/Bert_Arabic-SQuADv2-QA\" # run8 : pAP@10 = 0.435\n",
    "#bi_model_name = \"arabi-elidrisi/ArabicDistilBERT_QA\" #run 9 : pAP@10 = 0.343\n",
    "#bi_model_name = \"MMars/Question_Answering_AraBERT_xtreme_ar\" #run 10 : pAP@10 = 0.337\n",
    "# bi_model_name = \"abdalrahmanshahrour/ArabicQA\" # run 11 : pAP@10 = 0.304\n",
    "# bi_model_name = \"abdalrahmanshahrour/xtremeQA-ar\" # run 12 : pAP@10 = 0.120\n",
    "\n",
    "\n",
    "####################################### Checked models #######################################\n",
    "# bi_model_name = \"aubmindlab/bert-large-arabertv02\"\n",
    "\n",
    "# bi_model_name = \"sentence-transformers/distiluse-base-multilingual-cased-v1\" ## train : 0.48, dev : 0.12\n",
    "# bi_model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "# bi_model_name = \"wissamantoun/araelectra-base-artydiqa\" # run 1 : train:0.51 but dev near 0\n",
    "# bi_model_name = \"salti/AraElectra-base-finetuned-ARCD\" # run 2 : pAP@10 = 0.397\n",
    "# bi_model_name = \"ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA\" # run 3 : pAP@10 = 0.435\n",
    "# bi_model_name = \"timpal0l/mdeberta-v3-base-squad2\" # run 4 : pAP@10 = 0.367\n",
    "\n",
    "model_save_path = os.path.join(data_path, f'model/training_simcse-{bi_model_name}-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:18:48.090883700Z",
     "start_time": "2023-08-17T11:18:48.084108500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embedding_model Max Sequence Length: 128\n",
      "word_embedding_model dimension 768\n",
      "pooling_model sentence embedding dimension 768\n",
      "2023-08-17 04:18:50 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n",
    "#TODO : change max_seq_length to 384 or 512\n",
    "max_seq_length = 128\n",
    "word_embedding_model = models.Transformer(bi_model_name, max_seq_length=128)\n",
    "print(\"word_embedding_model Max Sequence Length:\", word_embedding_model.max_seq_length)\n",
    "print(\"word_embedding_model dimension\", word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "print(\"pooling_model sentence embedding dimension\", pooling_model.get_sentence_embedding_dimension())\n",
    "\n",
    "#TODO : change out_features to 512\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=512, activation_function=nn.Tanh())\n",
    "\n",
    "# bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:18:50.728737200Z",
     "start_time": "2023-08-17T11:18:49.603221200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# train_passage_dataloader = DataLoader(train_samples_passage, shuffle=True, batch_size=train_batch_size)\n",
    "# train_qp_dataloader = DataLoader(train_samples_qp, shuffle=True, batch_size=train_batch_size)\n",
    "train_qp_contrastive_dataloader = DataLoader(train_samples_qp_contrastive, shuffle=True, batch_size=train_batch_size)\n",
    "train_qp_triple_dataloader = DataLoader(train_samples_qp_triple, shuffle=True, batch_size=train_batch_size)\n",
    "# train_qp_multiple_negative_ranking_dataloader = DataLoader(train_samples_qp_multiple_negative_ranking, shuffle=True, batch_size=train_batch_size)\n",
    "train_qp_mr_tydi_triple = DataLoader(train_samples_mr_tydi_triple, shuffle=True, batch_size=train_batch_size)\n",
    "train_samples_qp_task_B_dataloader = DataLoader(train_samples_qp_task_B, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "train_biencoder_loss_MultipleNegativesRanking = losses.MultipleNegativesRankingLoss(bi_encoder)\n",
    "# train_biencoder_loss_Contrastive = losses.ContrastiveLoss(bi_encoder)\n",
    "train_biencoder_loss_Triple = losses.TripletLoss(model=bi_encoder)\n",
    "train_biencoder_loss_OnlineContrastive = losses.OnlineContrastiveLoss(bi_encoder)\n",
    "# train_biencoder_loss_CosineSimilarity = losses.CosineSimilarityLoss(bi_encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:19:09.133479900Z",
     "start_time": "2023-08-17T11:19:09.125479100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "#TODO : https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/multilingual/make_multilingual.py\n",
    "#teacher_model_name = 'fine_tine/simcse-model'   #Our monolingual teacher model, we want to convert to multiple languages\n",
    "#student_model_name = 'xlm-roberta-base'       #Multilingual base model we use to imitate the teacher model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T11:19:09.941263700Z",
     "start_time": "2023-08-17T11:19:09.933261400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-17 04:19:10 - Warmup-steps: 278\n",
      "train_batch_size 64\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee9ec6f9244d4c7c9c000e0d0710d1ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/1372 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7157deb0e0b4ab7aba927f875bc236f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-17 04:22:35 - Information Retrieval Evaluation on  dataset in epoch 0 after 301 steps:\n",
      "2023-08-17 04:22:36 - Queries: 25\n",
      "2023-08-17 04:22:36 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:22:36 - Score-Function: cos_sim\n",
      "2023-08-17 04:22:36 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:22:36 - Precision@10: 1.20%\n",
      "2023-08-17 04:22:36 - Recall@10: 1.64%\n",
      "2023-08-17 04:22:36 - MRR@10: 0.0140\n",
      "2023-08-17 04:22:36 - NDCG@10: 0.0108\n",
      "2023-08-17 04:22:36 - MAP@10: 0.0031\n",
      "2023-08-17 04:22:36 - Score-Function: dot_score\n",
      "2023-08-17 04:22:36 - Accuracy@10: 0.00%\n",
      "2023-08-17 04:22:36 - Precision@10: 0.00%\n",
      "2023-08-17 04:22:36 - Recall@10: 0.00%\n",
      "2023-08-17 04:22:36 - MRR@10: 0.0000\n",
      "2023-08-17 04:22:36 - NDCG@10: 0.0000\n",
      "2023-08-17 04:22:36 - MAP@10: 0.0000\n",
      "2023-08-17 04:26:00 - Information Retrieval Evaluation on  dataset in epoch 0 after 602 steps:\n",
      "2023-08-17 04:26:01 - Queries: 25\n",
      "2023-08-17 04:26:01 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:26:01 - Score-Function: cos_sim\n",
      "2023-08-17 04:26:01 - Accuracy@10: 20.00%\n",
      "2023-08-17 04:26:01 - Precision@10: 2.40%\n",
      "2023-08-17 04:26:01 - Recall@10: 6.46%\n",
      "2023-08-17 04:26:01 - MRR@10: 0.0480\n",
      "2023-08-17 04:26:01 - NDCG@10: 0.0372\n",
      "2023-08-17 04:26:01 - MAP@10: 0.0145\n",
      "2023-08-17 04:26:01 - Score-Function: dot_score\n",
      "2023-08-17 04:26:01 - Accuracy@10: 4.00%\n",
      "2023-08-17 04:26:01 - Precision@10: 0.80%\n",
      "2023-08-17 04:26:01 - Recall@10: 1.14%\n",
      "2023-08-17 04:26:01 - MRR@10: 0.0067\n",
      "2023-08-17 04:26:01 - NDCG@10: 0.0072\n",
      "2023-08-17 04:26:01 - MAP@10: 0.0022\n",
      "2023-08-17 04:29:26 - Information Retrieval Evaluation on  dataset in epoch 0 after 903 steps:\n",
      "2023-08-17 04:29:26 - Queries: 25\n",
      "2023-08-17 04:29:26 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:29:26 - Score-Function: cos_sim\n",
      "2023-08-17 04:29:26 - Accuracy@10: 20.00%\n",
      "2023-08-17 04:29:26 - Precision@10: 2.40%\n",
      "2023-08-17 04:29:26 - Recall@10: 4.22%\n",
      "2023-08-17 04:29:26 - MRR@10: 0.0357\n",
      "2023-08-17 04:29:26 - NDCG@10: 0.0286\n",
      "2023-08-17 04:29:26 - MAP@10: 0.0097\n",
      "2023-08-17 04:29:26 - Score-Function: dot_score\n",
      "2023-08-17 04:29:26 - Accuracy@10: 0.00%\n",
      "2023-08-17 04:29:26 - Precision@10: 0.00%\n",
      "2023-08-17 04:29:26 - Recall@10: 0.00%\n",
      "2023-08-17 04:29:26 - MRR@10: 0.0000\n",
      "2023-08-17 04:29:26 - NDCG@10: 0.0000\n",
      "2023-08-17 04:29:26 - MAP@10: 0.0000\n",
      "2023-08-17 04:32:51 - Information Retrieval Evaluation on  dataset in epoch 0 after 1204 steps:\n",
      "2023-08-17 04:32:52 - Queries: 25\n",
      "2023-08-17 04:32:52 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:32:52 - Score-Function: cos_sim\n",
      "2023-08-17 04:32:52 - Accuracy@10: 16.00%\n",
      "2023-08-17 04:32:52 - Precision@10: 2.40%\n",
      "2023-08-17 04:32:52 - Recall@10: 3.03%\n",
      "2023-08-17 04:32:52 - MRR@10: 0.0700\n",
      "2023-08-17 04:32:52 - NDCG@10: 0.0330\n",
      "2023-08-17 04:32:52 - MAP@10: 0.0146\n",
      "2023-08-17 04:32:52 - Score-Function: dot_score\n",
      "2023-08-17 04:32:52 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:32:52 - Precision@10: 0.80%\n",
      "2023-08-17 04:32:52 - Recall@10: 0.78%\n",
      "2023-08-17 04:32:52 - MRR@10: 0.0233\n",
      "2023-08-17 04:32:52 - NDCG@10: 0.0091\n",
      "2023-08-17 04:32:52 - MAP@10: 0.0028\n",
      "2023-08-17 04:34:46 - Information Retrieval Evaluation on  dataset after epoch 0:\n",
      "2023-08-17 04:34:46 - Queries: 25\n",
      "2023-08-17 04:34:46 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:34:46 - Score-Function: cos_sim\n",
      "2023-08-17 04:34:46 - Accuracy@10: 12.00%\n",
      "2023-08-17 04:34:46 - Precision@10: 2.40%\n",
      "2023-08-17 04:34:46 - Recall@10: 3.82%\n",
      "2023-08-17 04:34:46 - MRR@10: 0.0467\n",
      "2023-08-17 04:34:46 - NDCG@10: 0.0312\n",
      "2023-08-17 04:34:46 - MAP@10: 0.0137\n",
      "2023-08-17 04:34:46 - Score-Function: dot_score\n",
      "2023-08-17 04:34:46 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:34:46 - Precision@10: 0.80%\n",
      "2023-08-17 04:34:46 - Recall@10: 1.10%\n",
      "2023-08-17 04:34:46 - MRR@10: 0.0133\n",
      "2023-08-17 04:34:46 - NDCG@10: 0.0087\n",
      "2023-08-17 04:34:46 - MAP@10: 0.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/1372 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0d4e169f6594bbdaab918ee5bc6ec7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-17 04:38:11 - Information Retrieval Evaluation on  dataset in epoch 1 after 301 steps:\n",
      "2023-08-17 04:38:11 - Queries: 25\n",
      "2023-08-17 04:38:11 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:38:11 - Score-Function: cos_sim\n",
      "2023-08-17 04:38:11 - Accuracy@10: 12.00%\n",
      "2023-08-17 04:38:11 - Precision@10: 2.00%\n",
      "2023-08-17 04:38:11 - Recall@10: 2.82%\n",
      "2023-08-17 04:38:11 - MRR@10: 0.0700\n",
      "2023-08-17 04:38:11 - NDCG@10: 0.0315\n",
      "2023-08-17 04:38:11 - MAP@10: 0.0151\n",
      "2023-08-17 04:38:11 - Score-Function: dot_score\n",
      "2023-08-17 04:38:11 - Accuracy@10: 12.00%\n",
      "2023-08-17 04:38:11 - Precision@10: 1.20%\n",
      "2023-08-17 04:38:11 - Recall@10: 0.88%\n",
      "2023-08-17 04:38:11 - MRR@10: 0.0297\n",
      "2023-08-17 04:38:11 - NDCG@10: 0.0117\n",
      "2023-08-17 04:38:11 - MAP@10: 0.0031\n",
      "2023-08-17 04:41:36 - Information Retrieval Evaluation on  dataset in epoch 1 after 602 steps:\n",
      "2023-08-17 04:41:36 - Queries: 25\n",
      "2023-08-17 04:41:36 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:41:36 - Score-Function: cos_sim\n",
      "2023-08-17 04:41:36 - Accuracy@10: 12.00%\n",
      "2023-08-17 04:41:36 - Precision@10: 1.20%\n",
      "2023-08-17 04:41:36 - Recall@10: 2.01%\n",
      "2023-08-17 04:41:36 - MRR@10: 0.0390\n",
      "2023-08-17 04:41:36 - NDCG@10: 0.0193\n",
      "2023-08-17 04:41:36 - MAP@10: 0.0079\n",
      "2023-08-17 04:41:36 - Score-Function: dot_score\n",
      "2023-08-17 04:41:36 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:41:36 - Precision@10: 0.80%\n",
      "2023-08-17 04:41:36 - Recall@10: 1.44%\n",
      "2023-08-17 04:41:36 - MRR@10: 0.0267\n",
      "2023-08-17 04:41:36 - NDCG@10: 0.0138\n",
      "2023-08-17 04:41:36 - MAP@10: 0.0058\n",
      "2023-08-17 04:45:01 - Information Retrieval Evaluation on  dataset in epoch 1 after 903 steps:\n",
      "2023-08-17 04:45:02 - Queries: 25\n",
      "2023-08-17 04:45:02 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:45:02 - Score-Function: cos_sim\n",
      "2023-08-17 04:45:02 - Accuracy@10: 12.00%\n",
      "2023-08-17 04:45:02 - Precision@10: 1.60%\n",
      "2023-08-17 04:45:02 - Recall@10: 2.35%\n",
      "2023-08-17 04:45:02 - MRR@10: 0.0489\n",
      "2023-08-17 04:45:02 - NDCG@10: 0.0223\n",
      "2023-08-17 04:45:02 - MAP@10: 0.0092\n",
      "2023-08-17 04:45:02 - Score-Function: dot_score\n",
      "2023-08-17 04:45:02 - Accuracy@10: 12.00%\n",
      "2023-08-17 04:45:02 - Precision@10: 1.20%\n",
      "2023-08-17 04:45:02 - Recall@10: 0.88%\n",
      "2023-08-17 04:45:02 - MRR@10: 0.0144\n",
      "2023-08-17 04:45:02 - NDCG@10: 0.0089\n",
      "2023-08-17 04:45:02 - MAP@10: 0.0017\n",
      "2023-08-17 04:48:26 - Information Retrieval Evaluation on  dataset in epoch 1 after 1204 steps:\n",
      "2023-08-17 04:48:27 - Queries: 25\n",
      "2023-08-17 04:48:27 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:48:27 - Score-Function: cos_sim\n",
      "2023-08-17 04:48:27 - Accuracy@10: 4.00%\n",
      "2023-08-17 04:48:27 - Precision@10: 1.20%\n",
      "2023-08-17 04:48:27 - Recall@10: 1.71%\n",
      "2023-08-17 04:48:27 - MRR@10: 0.0200\n",
      "2023-08-17 04:48:27 - NDCG@10: 0.0147\n",
      "2023-08-17 04:48:27 - MAP@10: 0.0073\n",
      "2023-08-17 04:48:27 - Score-Function: dot_score\n",
      "2023-08-17 04:48:27 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:48:27 - Precision@10: 0.80%\n",
      "2023-08-17 04:48:27 - Recall@10: 0.31%\n",
      "2023-08-17 04:48:27 - MRR@10: 0.0090\n",
      "2023-08-17 04:48:27 - NDCG@10: 0.0053\n",
      "2023-08-17 04:48:27 - MAP@10: 0.0009\n",
      "2023-08-17 04:50:20 - Information Retrieval Evaluation on  dataset after epoch 1:\n",
      "2023-08-17 04:50:21 - Queries: 25\n",
      "2023-08-17 04:50:21 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:50:21 - Score-Function: cos_sim\n",
      "2023-08-17 04:50:21 - Accuracy@10: 4.00%\n",
      "2023-08-17 04:50:21 - Precision@10: 0.80%\n",
      "2023-08-17 04:50:21 - Recall@10: 1.14%\n",
      "2023-08-17 04:50:21 - MRR@10: 0.0200\n",
      "2023-08-17 04:50:21 - NDCG@10: 0.0109\n",
      "2023-08-17 04:50:21 - MAP@10: 0.0048\n",
      "2023-08-17 04:50:21 - Score-Function: dot_score\n",
      "2023-08-17 04:50:21 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:50:21 - Precision@10: 0.80%\n",
      "2023-08-17 04:50:21 - Recall@10: 1.54%\n",
      "2023-08-17 04:50:21 - MRR@10: 0.0137\n",
      "2023-08-17 04:50:21 - NDCG@10: 0.0097\n",
      "2023-08-17 04:50:21 - MAP@10: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/1372 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edc92aea90ba4424949b0fc870f9180b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-17 04:53:45 - Information Retrieval Evaluation on  dataset in epoch 2 after 301 steps:\n",
      "2023-08-17 04:53:46 - Queries: 25\n",
      "2023-08-17 04:53:46 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:53:46 - Score-Function: cos_sim\n",
      "2023-08-17 04:53:46 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:53:46 - Precision@10: 1.20%\n",
      "2023-08-17 04:53:46 - Recall@10: 1.35%\n",
      "2023-08-17 04:53:46 - MRR@10: 0.0267\n",
      "2023-08-17 04:53:46 - NDCG@10: 0.0134\n",
      "2023-08-17 04:53:46 - MAP@10: 0.0048\n",
      "2023-08-17 04:53:46 - Score-Function: dot_score\n",
      "2023-08-17 04:53:46 - Accuracy@10: 20.00%\n",
      "2023-08-17 04:53:46 - Precision@10: 2.00%\n",
      "2023-08-17 04:53:46 - Recall@10: 3.55%\n",
      "2023-08-17 04:53:46 - MRR@10: 0.0407\n",
      "2023-08-17 04:53:46 - NDCG@10: 0.0247\n",
      "2023-08-17 04:53:46 - MAP@10: 0.0073\n",
      "2023-08-17 04:57:10 - Information Retrieval Evaluation on  dataset in epoch 2 after 602 steps:\n",
      "2023-08-17 04:57:11 - Queries: 25\n",
      "2023-08-17 04:57:11 - Corpus: 1266\n",
      "\n",
      "2023-08-17 04:57:11 - Score-Function: cos_sim\n",
      "2023-08-17 04:57:11 - Accuracy@10: 8.00%\n",
      "2023-08-17 04:57:11 - Precision@10: 1.20%\n",
      "2023-08-17 04:57:11 - Recall@10: 1.35%\n",
      "2023-08-17 04:57:11 - MRR@10: 0.0300\n",
      "2023-08-17 04:57:11 - NDCG@10: 0.0146\n",
      "2023-08-17 04:57:11 - MAP@10: 0.0058\n",
      "2023-08-17 04:57:11 - Score-Function: dot_score\n",
      "2023-08-17 04:57:11 - Accuracy@10: 16.00%\n",
      "2023-08-17 04:57:11 - Precision@10: 1.60%\n",
      "2023-08-17 04:57:11 - Recall@10: 2.98%\n",
      "2023-08-17 04:57:11 - MRR@10: 0.0264\n",
      "2023-08-17 04:57:11 - NDCG@10: 0.0188\n",
      "2023-08-17 04:57:11 - MAP@10: 0.0051\n",
      "2023-08-17 05:00:35 - Information Retrieval Evaluation on  dataset in epoch 2 after 903 steps:\n",
      "2023-08-17 05:00:36 - Queries: 25\n",
      "2023-08-17 05:00:36 - Corpus: 1266\n",
      "\n",
      "2023-08-17 05:00:36 - Score-Function: cos_sim\n",
      "2023-08-17 05:00:36 - Accuracy@10: 8.00%\n",
      "2023-08-17 05:00:36 - Precision@10: 1.20%\n",
      "2023-08-17 05:00:36 - Recall@10: 1.35%\n",
      "2023-08-17 05:00:36 - MRR@10: 0.0280\n",
      "2023-08-17 05:00:36 - NDCG@10: 0.0140\n",
      "2023-08-17 05:00:36 - MAP@10: 0.0053\n",
      "2023-08-17 05:00:36 - Score-Function: dot_score\n",
      "2023-08-17 05:00:36 - Accuracy@10: 8.00%\n",
      "2023-08-17 05:00:36 - Precision@10: 0.80%\n",
      "2023-08-17 05:00:36 - Recall@10: 0.31%\n",
      "2023-08-17 05:00:36 - MRR@10: 0.0180\n",
      "2023-08-17 05:00:36 - NDCG@10: 0.0072\n",
      "2023-08-17 05:00:36 - MAP@10: 0.0018\n",
      "2023-08-17 05:04:00 - Information Retrieval Evaluation on  dataset in epoch 2 after 1204 steps:\n",
      "2023-08-17 05:04:01 - Queries: 25\n",
      "2023-08-17 05:04:01 - Corpus: 1266\n",
      "\n",
      "2023-08-17 05:04:01 - Score-Function: cos_sim\n",
      "2023-08-17 05:04:01 - Accuracy@10: 12.00%\n",
      "2023-08-17 05:04:01 - Precision@10: 1.60%\n",
      "2023-08-17 05:04:01 - Recall@10: 2.35%\n",
      "2023-08-17 05:04:01 - MRR@10: 0.0350\n",
      "2023-08-17 05:04:01 - NDCG@10: 0.0199\n",
      "2023-08-17 05:04:01 - MAP@10: 0.0074\n",
      "2023-08-17 05:04:01 - Score-Function: dot_score\n",
      "2023-08-17 05:04:01 - Accuracy@10: 16.00%\n",
      "2023-08-17 05:04:01 - Precision@10: 1.60%\n",
      "2023-08-17 05:04:01 - Recall@10: 2.98%\n",
      "2023-08-17 05:04:01 - MRR@10: 0.0242\n",
      "2023-08-17 05:04:01 - NDCG@10: 0.0178\n",
      "2023-08-17 05:04:01 - MAP@10: 0.0044\n",
      "2023-08-17 05:05:55 - Information Retrieval Evaluation on  dataset after epoch 2:\n",
      "2023-08-17 05:05:55 - Queries: 25\n",
      "2023-08-17 05:05:55 - Corpus: 1266\n",
      "\n",
      "2023-08-17 05:05:55 - Score-Function: cos_sim\n",
      "2023-08-17 05:05:55 - Accuracy@10: 12.00%\n",
      "2023-08-17 05:05:55 - Precision@10: 1.60%\n",
      "2023-08-17 05:05:55 - Recall@10: 2.35%\n",
      "2023-08-17 05:05:55 - MRR@10: 0.0350\n",
      "2023-08-17 05:05:55 - NDCG@10: 0.0199\n",
      "2023-08-17 05:05:55 - MAP@10: 0.0074\n",
      "2023-08-17 05:05:55 - Score-Function: dot_score\n",
      "2023-08-17 05:05:55 - Accuracy@10: 12.00%\n",
      "2023-08-17 05:05:55 - Precision@10: 1.20%\n",
      "2023-08-17 05:05:55 - Recall@10: 1.65%\n",
      "2023-08-17 05:05:55 - MRR@10: 0.0160\n",
      "2023-08-17 05:05:55 - NDCG@10: 0.0114\n",
      "2023-08-17 05:05:55 - MAP@10: 0.0025\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#  asymmetric semantic search\n",
    "warmup_steps = math.ceil(len(train_qp_triple_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# logging.info(\"Performance before training\")\n",
    "# dev_evaluator(model)\n",
    "#RerankingEvaluator\n",
    "#InformationRetrievalEvaluator\n",
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/quora_duplicate_questions/training_OnlineContrastiveLoss.py\n",
    "\n",
    "\n",
    "#Task B data -> good results\n",
    "\n",
    "# bi_encoder.fit(\n",
    "#           train_objectives=[\n",
    "#                         (train_samples_qp_task_B_dataloader, train_biencoder_loss_MultipleNegativesRanking)],  epochs=3)\n",
    "\n",
    "dev_evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "                                df_query_dev.groupby('qid')['query'].apply(str).to_dict(),\n",
    "                                df_passage.groupby('pid')['passage'].apply(str).to_dict(),\n",
    "                                df_qppair_dev.groupby('qid')['docid'].apply(set).to_dict(),\n",
    "                                accuracy_at_k = [10],\n",
    "                                precision_recall_at_k  = [10],\n",
    "                                map_at_k = [10], mrr_at_k=[10]\n",
    "                                #, score_functions='cos_sim'\n",
    "                                )\n",
    "\n",
    "# multi-task training\n",
    "print(\"train_batch_size\", train_batch_size)\n",
    "bi_encoder.fit(\n",
    "          train_objectives=[\n",
    "                        # (train_passage_dataloader, train_biencoder_loss_MultipleNegativesRanking), #SimCSE\n",
    "                        (train_qp_contrastive_dataloader, train_biencoder_loss_OnlineContrastive),\n",
    "                        # (train_qp_multiple_negative_ranking_dataloader, train_biencoder_loss_MultipleNegativesRanking),\n",
    "\n",
    "                        (train_qp_mr_tydi_triple, train_biencoder_loss_MultipleNegativesRanking),\n",
    "                        # (train_samples_qp_task_B_dataloader, train_biencoder_loss_MultipleNegativesRanking),\n",
    "                        # (train_qp_triple_dataloader, train_biencoder_loss_Triple)\n",
    "              ],\n",
    "              evaluator=dev_evaluator,\n",
    "              epochs=num_epochs,\n",
    "              evaluation_steps=301,\n",
    "              warmup_steps=warmup_steps,\n",
    "              # output_path=\"D:/IR/Quran_QA/Task A/data/fine_tune_simcse-model_MultiTaskTraining_3epoch_64batchsize_contraintive_multiple_negative_ranking\"\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:05:55.928489700Z",
     "start_time": "2023-08-17T11:19:10.752443800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa10ff843a3f40e3af7bc0a0582451ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f81503577cfa404d8c2392106b62d5f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33495840b44a4f42b2f5155e53be8297"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd06f2be3af6446fb5a7e02b27a75347"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "passage_embeddings = bi_encoder.encode(df_passage['passage'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "query_train_embeddings = bi_encoder.encode(df_query_train['query'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "query_dev_embeddings = bi_encoder.encode(df_query_dev['query'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "query_tset_embeddings = bi_encoder.encode(df_query_test['query'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "df_passage['embedding'] = passage_embeddings.cpu().numpy().tolist()\n",
    "df_query_train['embedding'] = query_train_embeddings.cpu().numpy().tolist()\n",
    "df_query_dev['embedding'] = query_dev_embeddings.cpu().numpy().tolist()\n",
    "df_query_test['embedding'] = query_tset_embeddings.cpu().numpy().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:05:57.346251900Z",
     "start_time": "2023-08-17T12:05:55.928489700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Semantic Search"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T05:46:25.782885900Z",
     "start_time": "2023-08-11T05:44:41.894786800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-10 22:44:41 - Warmup-steps: 45\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcc6162ce81a487ab3117f9ea8f9561c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/450 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a806fa4399334ed995b40f378b05711f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarmup-steps: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(warmup_steps))\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# logging.info(\"Performance before training\")\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# dev_evaluator(model)\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[43mbi_encoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_objectives\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_biencoder_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_biencoder_loss\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# evaluator=dev_evaluator,\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m          \u001B[49m\u001B[43mevaluation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m          \u001B[49m\u001B[43mwarmup_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarmup_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# output_path=model_save_path\u001B[39;49;00m\n\u001B[0;32m     13\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Users\\gargo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:722\u001B[0m, in \u001B[0;36mSentenceTransformer.fit\u001B[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001B[0m\n\u001B[0;32m    720\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    721\u001B[0m     loss_value \u001B[38;5;241m=\u001B[39m loss_model(features, labels)\n\u001B[1;32m--> 722\u001B[0m     \u001B[43mloss_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    723\u001B[0m     torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(loss_model\u001B[38;5;241m.\u001B[39mparameters(), max_grad_norm)\n\u001B[0;32m    724\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mC:\\Users\\gargo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Users\\gargo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\\fine_tune/simcse-model all passage embeddings \n",
      "num_epochs = 3\n",
      "Format check: Passed\n",
      " map_cut_10  recip_rank\n",
      "   0.524258    0.657998\n"
     ]
    }
   ],
   "source": [
    "tag = \"SimCSE_bitrain40\"\n",
    "hits = util.semantic_search(query_train_embeddings, passage_embeddings, top_k=10)\n",
    "df_run = save_query_passage_retrieval(hits, tag, run_save=True, df_query=df_query_train)\n",
    "\n",
    "print(bi_model_name, \"all passage embeddings\", \"\\nnum_epochs =\", num_epochs,)\n",
    "! python QQA23_TaskA_eval.py \\\n",
    "    -r \"../data/runs/SimCSE_bitrain40.tsv\" \\\n",
    "    -q \"../data/qrels/QQA23_TaskA_qrels_train.gold\"\n",
    "# df_run"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:05:57.821967200Z",
     "start_time": "2023-08-17T12:05:57.347251400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\\fine_tune/simcse-model all passage embeddings\n",
      "Format check: Passed\n",
      " map_cut_10  recip_rank\n",
      "   0.108253    0.169333\n"
     ]
    }
   ],
   "source": [
    "tag = \"SimCSE_bidev40\"\n",
    "top_k = 10\n",
    "hits = util.semantic_search(query_dev_embeddings, passage_embeddings, top_k=top_k)\n",
    "# hits = util.cos_sim(query_dev_embeddings, passage_embeddings)\n",
    "df_run = save_query_passage_retrieval(hits, tag, run_save=True, df_query=df_query_dev, top_k=top_k)\n",
    "\n",
    "print(bi_model_name, \"all passage embeddings\")\n",
    "! python QQA23_TaskA_eval.py \\\n",
    "    -r \"../data/runs/SimCSE_bidev40.tsv\" \\\n",
    "    -q \"../data/qrels/QQA23_TaskA_qrels_dev.gold\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T12:05:58.214232600Z",
     "start_time": "2023-08-17T12:05:57.821967200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "tag = \"SimCSE_bitest40\"\n",
    "hits = util.semantic_search(query_tset_embeddings, passage_embeddings, top_k=top_k)\n",
    "# hits = util.cos_sim(query_dev_embeddings, passage_embeddings)\n",
    "df_run = save_query_passage_retrieval(hits, tag, run_save=True, df_query=df_query_test, top_k=top_k)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:00.391449600Z",
     "start_time": "2023-08-17T10:45:00.375822500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "../data\\fine_tune/simcse-model BM25 hits with BiEncoder\n",
      "Format check: Passed\n",
      " map_cut_10  recip_rank\n",
      "   0.088159    0.212381\n"
     ]
    }
   ],
   "source": [
    "tag = \"SimCSE_bmbiencd\"\n",
    "bm_num_results = 15\n",
    "BM25_model = pt.BatchRetrieve(index, controls = {\"wmodel\": \"BM25\"}, num_results=bm_num_results)\n",
    "\n",
    "bm25_biencoder_hit= []\n",
    "\n",
    "for query in df_query_dev['query'].tolist():\n",
    "    bm25_result = BM25_model.search(query)\n",
    "    bm25_related_passage = bm25_result['docno'].tolist()\n",
    "    passage =  df_passage[df_passage['pid'].isin(bm25_related_passage)]['passage'].tolist()\n",
    "\n",
    "    try:\n",
    "        query_embedding = bi_encoder.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "        passage_embeddings = bi_encoder.encode(passage, convert_to_tensor=True, show_progress_bar=False)\n",
    "        # TODO\n",
    "        '''\n",
    "        check similarity between query and passage, with methods is better for this task?\n",
    "        util.dot_score\n",
    "        util.cos_sim\n",
    "        util.pairwise_dot_score\n",
    "        util.pairwise_cos_sim\n",
    "        '''\n",
    "        hit = util.semantic_search(query_embedding, passage_embeddings, top_k=10)[0]\n",
    "        mapping = {index : row['docno'] for index, row in bm25_result.iterrows()}\n",
    "\n",
    "    except:\n",
    "        #len passage is 0 but why ?\n",
    "        print(f\"len passage : {len(passage)}, qury : {query}\")\n",
    "        query_embedding = bi_encoder.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "        passage = df_passage['passage'].tolist()\n",
    "        passage_embeddings = bi_encoder.encode(passage, convert_to_tensor=True, show_progress_bar=False)\n",
    "\n",
    "        hit = util.semantic_search(query_embedding, passage_embeddings, top_k=top_k)[0]\n",
    "        mapping = {index : row['pid'] for index, row in df_passage.iterrows()}\n",
    "\n",
    "    for i in range(len(hit)):\n",
    "        hit[i]['corpus_id'] = mapping[hit[i]['corpus_id']]\n",
    "    hit = sorted(hit, key=lambda x: x['score'], reverse=True)\n",
    "    bm25_biencoder_hit.append(hit)\n",
    "\n",
    "df_run = save_query_passage_retrieval(bm25_biencoder_hit, tag, run_save=True, df_query=df_query_dev)\n",
    "\n",
    "print(bi_model_name, \"BM25 hits with BiEncoder\")\n",
    "!python QQA23_TaskA_eval.py \\\n",
    "    -r \"../data/runs/SimCSE_bmbiencd.tsv\" \\\n",
    "    -q \"../data/qrels/QQA23_TaskA_qrels_dev.gold\"\n",
    "# df_run"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.771388800Z",
     "start_time": "2023-08-17T10:45:00.391449600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Re-ranker (Cross-Encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T05:47:42.914442500Z",
     "start_time": "2023-08-11T05:47:22.960408800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d69556b7ac9d45e0b85d4cd432ad3f28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a867eb20b7c946c5a9c55f405b333b95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36b3a37474e0422b9f4138639d5c3c57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nhttps://github.com/Guzpenha/transformer_rankers\\nhttps://colab.research.google.com/drive/1wGmaO3emC7Sg-tA7nGehIQ2vjOLN9S5e?usp=sharing#scrollTo=y9ps5zmOHxe4\\n'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO:\n",
    "'''\n",
    "https://github.com/Guzpenha/transformer_rankers\n",
    "https://colab.research.google.com/drive/1wGmaO3emC7Sg-tA7nGehIQ2vjOLN9S5e?usp=sharing#scrollTo=y9ps5zmOHxe4\n",
    "'''\n",
    "\n",
    "# cross_model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "# cross_model_name = \"cross-encoder/ms-marco-TinyBERT-L-2\"\n",
    "# cross_model_name = \"distilroberta-base\"\n",
    "# cross_model_name = \"amberoad/bert-multilingual-passage-reranking-msmarco\"\n",
    "# cross_model_name = \"ZeyadAhmed/AraElectra-Arabic-SQuADv2-CLS\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.819909300Z",
     "start_time": "2023-08-17T10:45:01.773000800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "#https://sbert.net/docs/package_reference/cross_encoder.html\n",
    "\n",
    "# cross_encoder = CrossEncoder(cross_model_name)\n",
    "# warmup_steps = math.ceil(len(train_qp_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "# logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "#\n",
    "# cross_encoder.fit(train_qp_dataloader,\n",
    "#           # evaluator=dev_evaluator,\n",
    "#           epochs=num_epochs,\n",
    "#           evaluation_steps=100,\n",
    "#           warmup_steps=warmup_steps,\n",
    "#           output_path=model_save_path\n",
    "#           )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.819909300Z",
     "start_time": "2023-08-17T10:45:01.788659100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# tag = \"SimCSE_cross\"\n",
    "# df_final = pd.DataFrame()\n",
    "# for qid, filter_passages in df_run.groupby('qid'):\n",
    "#     cross_inp = []\n",
    "#     q = df_query_dev[df_query_dev['qid'] == qid]\n",
    "#     for x in filter_passages.values:\n",
    "#         p = df_passage[df_passage['pid'] == x[2]]\n",
    "#         cross_inp.append([q['query'].tolist()[0], p['passage'].tolist()[0]])\n",
    "#\n",
    "#     similarity_scores = cross_encoder.predict(cross_inp, show_progress_bar=False)\n",
    "#\n",
    "#     # Sort the scores in decreasing order\n",
    "#     sim_scores_argsort = reversed(np.argsort(similarity_scores))\n",
    "#\n",
    "#     print(len(similarity_scores))\n",
    "#     print(len(filter_passages['pid'].values))\n",
    "#     df_temp = pd.DataFrame({'qid': qid, 'pid': filter_passages['pid'].values, 'score': similarity_scores})\n",
    "#     df_temp = df_temp.sort_values(by=['score'], ascending=False)[:10]\n",
    "#     df_temp['rank'] = range(1, len(df_temp) + 1)\n",
    "#\n",
    "#     df_final = pd.concat([df_final, df_temp], ignore_index=True)\n",
    "#\n",
    "# df_final = save_query_passage_retrieval(df_final, tag, run_save=True)\n",
    "#\n",
    "# print(\"cross-encoder model name\", cross_model_name)\n",
    "# ! python QQA23_TaskA_eval.py \\\n",
    "#     -r \"../data/runs/SimCSE_cross.tsv\" \\\n",
    "#     -q \"../data/qrels/QQA23_TaskA_qrels_train.gold\"\n",
    "# df_final"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.819909300Z",
     "start_time": "2023-08-17T10:45:01.819909300Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# ! python QQA23_TaskA_eval.py \\\n",
    "#     -r \"../data/runs/BM25_Final.tsv\" \\\n",
    "#     -q \"../data/qrels/QQA23_TaskA_qrels_dev.gold\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.835534500Z",
     "start_time": "2023-08-17T10:45:01.819909300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.858344800Z",
     "start_time": "2023-08-17T10:45:01.835534500Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! python QQA23_TaskA_eval.py \\\n",
    "#     -r \"../data/runs/bigIR_BM25.tsv\" \\\n",
    "#     -q \"../data/qrels/QQA23_TaskA_qrels_dev.gold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:45:01.858344800Z",
     "start_time": "2023-08-17T10:45:01.842309100Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! python QQA23_TaskA_eval.py \\\n",
    "#     -r \"../data/runs/dev_perfect.tsv\" \\\n",
    "#     -q \"../data/qrels/QQA23_TaskA_qrels_dev.gold\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
